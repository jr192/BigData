{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BDCC project 1 \n",
    "\n",
    "_[Big Data and Cloud Computing](http://www.dcc.fc.up.pt/~edrdo/aulas/bdcc), DCC/FCUP_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code necessary to run from the command line "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\" :\n",
    "    # This block is required to run the program from the command line\n",
    "    # in interface with a single Spark instance\n",
    "    from pyspark import SparkContext\n",
    "    from pyspark.sql import SparkSession\n",
    "    \n",
    "    spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName(\"BDCCp1\")\\\n",
    "        .master(\"local[*]\")\\\n",
    "        .getOrCreate()\n",
    "    sc = spark.sparkContext\n",
    "    sc.setLogLevel(\"WARN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Provided code - auxilliary functions\n",
    "\n",
    "__You should not need to edit these.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### loadMovieLensData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "def readCSV(file, debug=False):\n",
    "    if debug:\n",
    "      print('Reading ' + file)\n",
    "    return spark.read.csv(file, inferSchema=True, header=True)\n",
    "\n",
    "def readParquet(file, debug=False): \n",
    "    if debug:\n",
    "       print('Reading ' + file)\n",
    "    return spark.read.parquet(file)\n",
    "\n",
    "def loadMovieLensData(path, format='parquet', debug=False):\n",
    "    if format == 'parquet':\n",
    "       movies = readParquet(path +'/movies.parquet', debug)\n",
    "       ratings = readParquet(path +'/ratings.parquet', debug)\n",
    "       tags = readParquet(path +'/tags.parquet', debug)\n",
    "    else:\n",
    "       movies = readCSV(path +'/movies.csv', debug)\n",
    "       ratings = readCSV(path +'/ratings.csv', debug)\n",
    "       tags = readCSV(path +'/tags.csv', debug)\n",
    "    \n",
    "    tags = tags.withColumn('tagl', F.explode(F.split(F.lower(F.col('tag')),'[ \\*\\+\\&\\/\\%\\-\\$\\#\\'\\)\\(\\[\\[\\],.!?;:\\t\\n\"]+')))\\\n",
    "            .drop('tag')\\\n",
    "            .withColumnRenamed('tagl','tag')\n",
    "    if (debug):\n",
    "        print('> movies')\n",
    "        movies.printSchema()\n",
    "        movies.show()\n",
    "        print('> ratings')\n",
    "        ratings.printSchema()\n",
    "        ratings.show()\n",
    "        print('> tags')\n",
    "        tags.printSchema()\n",
    "        tags.show()\n",
    "    return (movies, ratings, tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### writeCSV / writeParquet (use them to write a data frame to CSV or Parquet format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeCSV(df, path): \n",
    "    df.write.csv(path, header=True, mode='overwrite')\n",
    "\n",
    "def writeParquet(df,path):\n",
    "    df.write.parquet(path, mode='overwrite')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### createTagListDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTagListDF(csvTagList):\n",
    "    return spark.createDataFrame([ (t,) for t in csvTagList.split(' ')], ['tag'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definition of functions available only in Spark 2.4 (GCP Spark instances run Spark 2.3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import ArrayType,IntegerType\n",
    "\n",
    "# Define F.array_intersect if not defined (Spark version < 2.4)\n",
    "if not hasattr(F,'array_intersect'):\n",
    "  F.array_intersect = spark.udf\\\n",
    "    .register('array_intersect', \n",
    "       lambda x,y: list(set(x) & set(y)), ArrayType(IntegerType()))\n",
    "\n",
    "# Define F.array_union if not defined (Spark version < 2.4)\n",
    "if not hasattr(F,'array_union'):\n",
    "  F.array_union = spark.udf\\\n",
    "    .register('array_union', \n",
    "       lambda x,y: list(set(x) | set(y)), ArrayType(IntegerType()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to define \n",
    "\n",
    "__This is the section that will be evaluated.__\n",
    "\n",
    "__Include your code for the various functions required in the assigment below.__\n",
    "\n",
    "__You may include other auxilliary functions required for computation here\n",
    "but NOT test code (see below).__\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tfidfTags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "    \n",
    "def getTF(tags, debug=False):\n",
    "    # TODO\n",
    "    movie_tags = tags\\\n",
    "                .groupBy('tag','movieId')\\\n",
    "                .agg(F.count('movieId').alias('f'))\n",
    "    if debug:\n",
    "        movie_tags.orderBy('tag', 'movieId',ascending=False).show()\n",
    "    \n",
    "    movie_tags_max = movie_tags\\\n",
    "                 .groupBy('movieId')\\\n",
    "                 .agg(F.max('f').alias('f_max'))\n",
    "    if debug:\n",
    "        movie_tags_max.orderBy('movieId',ascending=False).show()\n",
    "    \n",
    "    TF = movie_tags.join(movie_tags_max, 'movieId')\\\n",
    "             .withColumn('TF', F.col('f') / F.col('f_max'))    \n",
    "    return TF\n",
    "\n",
    "def getIDF(tags, debug=False):\n",
    "    n_movies = tags\\\n",
    "           .groupBy('tag')\\\n",
    "           .agg(F.countDistinct('movieId').alias('n'))\n",
    "    if debug:\n",
    "        n_movies.orderBy('tag',ascending=False).show()\n",
    "        \n",
    "    size_of_N = tags.select('movieId').distinct().count()\n",
    "    if debug:\n",
    "        print(\"|N| = %d\" % size_of_N)\n",
    "        \n",
    "    IDF = n_movies\\\n",
    "            .withColumn('IDF', F.log2(size_of_N / F.col('n')))\\\n",
    "            \n",
    "    return IDF\n",
    "    \n",
    "def tfidfTags(tags, debug=False):\n",
    "    TF = getTF(tags, debug)\n",
    "    if debug:\n",
    "        TF.orderBy(['tag','TF'],ascending=[1,0]).show(TF.count())\n",
    "    \n",
    "    IDF = getIDF(tags, debug)\n",
    "    if debug:\n",
    "        IDF.orderBy(['IDF','n'], ascending=[0,1]).show(IDF.count())\n",
    "\n",
    "    TF_IDF = TF\\\n",
    "      .join(IDF,'tag')\\\n",
    "      .withColumn('TF_IDF',F.col('TF') * F.col('IDF'))\n",
    "        \n",
    "    if debug:\n",
    "        TF_IDF.orderBy(['tag','TF_IDF','movieId'],ascending=[1,0,1]).show(TF_IDF.count())\n",
    "        \n",
    "    return TF_IDF\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### recommendByTag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "def recommendByTag(singleTag, TFIDF_tags, movies, min_fmax=10, numberOfResults=10, debug=False):\n",
    "    # TODO\n",
    "    \n",
    "    df = TFIDF_tags.join(movies, 'movieId')  \n",
    "    if debug:\n",
    "        df.show()\n",
    "    \n",
    "    df_b = df.filter(df['tag'] == singleTag)\\\n",
    "        .filter(df.f_max>=min_fmax)\\\n",
    "        .select('movieId','title','TF_IDF')\\\n",
    "        .orderBy('TF_IDF','title',ascending=[0,1])\\\n",
    "        .limit(numberOfResults)\n",
    "  \n",
    "    return df_b\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### recommendByTags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+------------------+\n",
      "|movieId|               title|        SUM_TF_IDF|\n",
      "+-------+--------------------+------------------+\n",
      "|   1333|   Birds, The (1963)|11.910970878541328|\n",
      "|   6299|Winged Migration ...| 9.407798850221976|\n",
      "|    965|39 Steps, The (1935)| 7.729726945109338|\n",
      "|   1086|Dial M for Murder...| 7.729726945109338|\n",
      "|   2183|Man Who Knew Too ...| 7.729726945109338|\n",
      "|    908|North by Northwes...| 7.729726945109338|\n",
      "|    930|    Notorious (1946)| 7.729726945109338|\n",
      "|   1219|       Psycho (1960)| 7.729726945109338|\n",
      "|    904|  Rear Window (1954)| 7.729726945109338|\n",
      "|    928|      Rebecca (1940)| 7.729726945109338|\n",
      "+-------+--------------------+------------------+\n",
      "\n",
      "+-------+--------------------+------------------+\n",
      "|movieId|               title|        SUM_TF_IDF|\n",
      "+-------+--------------------+------------------+\n",
      "|  99114|Django Unchained ...|18.963598863331505|\n",
      "| 128360|The Hateful Eight...|18.963598863331505|\n",
      "|  68157|Inglourious Baste...|18.423496364059403|\n",
      "|  53519|  Death Proof (2007)|18.139094564925784|\n",
      "|   1089|Reservoir Dogs (1...|17.563601631810386|\n",
      "|   6874|Kill Bill: Vol. 1...|17.372692918421144|\n",
      "|   7438|Kill Bill: Vol. 2...| 17.11991564050761|\n",
      "|    296| Pulp Fiction (1994)| 17.08153314699584|\n",
      "|  52281|   Grindhouse (2007)|16.717909524252775|\n",
      "|   1729| Jackie Brown (1997)| 16.54271390205514|\n",
      "+-------+--------------------+------------------+\n",
      "\n",
      "+-------+--------------------+------------------+\n",
      "|movieId|               title|        SUM_TF_IDF|\n",
      "+-------+--------------------+------------------+\n",
      "|    316|     Stargate (1994)|14.879638377998102|\n",
      "|   5378|Star Wars: Episod...| 14.85875647213171|\n",
      "|  27611|Battlestar Galact...|14.737055348050301|\n",
      "|  33004|Hitchhiker's Guid...|   14.563712248483|\n",
      "|   1196|Star Wars: Episod...|14.419259665510246|\n",
      "|    260|Star Wars: Episod...|14.352277775109407|\n",
      "| 122918|Guardians of the ...|14.077773192728628|\n",
      "|  59392|Stargate: The Ark...|14.077773192728628|\n",
      "|  68237|         Moon (2009)| 13.96149221769939|\n",
      "|   1210|Star Wars: Episod...|13.913675625105618|\n",
      "+-------+--------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from functools import reduce\n",
    "from pyspark.sql import DataFrame\n",
    "\n",
    "#usado para juntar os resultados num só\n",
    "def unionAll(*dfs):\n",
    "    return reduce(DataFrame.unionAll,dfs)\n",
    "\n",
    "def recommendByTags(searchTags, TFIDF_tags, movies, min_fmax=10, numberOfResults=10, debug=False):\n",
    "    searchTagsDF = createTagListDF(searchTags)\n",
    "    tags = searchTags.split()\n",
    "    if debug:\n",
    "        print('> Search tags DF: ' + searchTags)\n",
    "        searchTagsDF.show()\n",
    "    # TODO\n",
    "    df = TFIDF_tags.join(movies, 'movieId')  \n",
    "    c=0\n",
    "    for x in tags:\n",
    "        df_b = df.filter(df['tag'] == x)\\\n",
    "            .filter(df.f_max>=min_fmax)\\\n",
    "            .select('movieId','title','TF_IDF')\\\n",
    "            .orderBy(['TF_IDF','title'],ascending=[0,1])\n",
    "        \n",
    "        if c==0: #se é o primeiro\n",
    "            df_f=df_b\n",
    "        else:\n",
    "            df_f= unionAll(df_f,df_b)\n",
    "        c=c+1\n",
    "        \n",
    "    df_f = df_f\\\n",
    "           .groupBy('movieId','title')\\\n",
    "           .agg(F.sum('TF_IDF').alias('SUM_TF_IDF'))\\\n",
    "           .orderBy(['SUM_TF_IDF','title'],ascending=[0,1])\\\n",
    "           .limit(numberOfResults)\n",
    "    \n",
    "    if debug:\n",
    "        df_f.show()\n",
    "    \n",
    "    return df_f\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### jiMovieSimilarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import ArrayType,IntegerType\n",
    "\n",
    "\n",
    "def jiMovieSimilarity(ratings, minRatings=10, debug=False):\n",
    "\n",
    "    data = ratings.withColumnRenamed('movieId','m1').filter(ratings.rating >=4.0)\n",
    "    \n",
    "    df_m1 = data\\\n",
    "            .groupBy('m1')\\\n",
    "            .agg(F.collect_set(ratings.userId)\\\n",
    "                 .alias('fu1')\\\n",
    "               )\\\n",
    "    \n",
    "    #renoemar para conseguir comparar os valores m1 e m2\n",
    "    df_m2 = df_m1\\\n",
    "        .withColumnRenamed('m1', 'm2')\\\n",
    "        .withColumnRenamed('fu1', 'fu2')\n",
    "    \n",
    "    prod = df_m1\\\n",
    "        .crossJoin(df_m2)\\\n",
    "        .filter(df_m1.m1 < df_m2.m2)\n",
    "    \n",
    "    if debug:\n",
    "        prod.show()\n",
    "    if debug:\n",
    "        df_m1.show()\n",
    "        \n",
    "    prod2 = prod\\\n",
    "       .withColumn('i',\\\n",
    "           F.size(F.array_intersect(df_m1.fu1,df_m2.fu2)))\\\n",
    "       .withColumn('u',\\\n",
    "           F.size(F.array_union(df_m1.fu1, df_m2.fu2)))\\\n",
    "       .drop('fu1','fu2')\n",
    "   \n",
    "    if debug:\n",
    "        prod2.show()\n",
    "        \n",
    "    result = prod2\\\n",
    "       .withColumn('JI', prod2.i / prod2.u) #aplicar a formula do jaccard index\n",
    "    \n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### recommendBySimilarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommendBySimilarity(movieId, movies, jiForMovies, numberOfResults=10, debug=False):\n",
    "    # TODO\n",
    "    if debug:\n",
    "        jiForMovies.show()\n",
    "    #df.show()\n",
    "    \n",
    "    df = jiForMovies.filter(movieId == jiForMovies.m1).select('m2','JI').orderBy('JI',ascending=[0])\n",
    "    df2 = jiForMovies.filter(movieId == jiForMovies.m2).select('m1','JI').orderBy('JI',ascending=[0])\n",
    "    \n",
    "    df = df.withColumnRenamed('m2', 'movieId') #renomear para ser mais facil usar o join\n",
    "    df2 = df2.withColumnRenamed('m1', 'movieId') \n",
    "    \n",
    "    if debug:\n",
    "        df.show()\n",
    "        df2.show()\n",
    "    \n",
    "    result = df.union(df2)\n",
    "    result = result.join(movies,'movieId')\n",
    "    \n",
    "    result = result.select('movieId','title','JI').orderBy('JI',ascending=[0]).limit(numberOfResults)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify input data set and load it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading gs://bddcc_up201405426/p1/medium1/movies.csv\n",
      "Reading gs://bddcc_up201405426/p1/medium1/ratings.csv\n",
      "Reading gs://bddcc_up201405426/p1/medium1/tags.csv\n",
      "> movies\n",
      "root\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      "\n",
      "+-------+--------------------+\n",
      "|movieId|               title|\n",
      "+-------+--------------------+\n",
      "|      1|    Toy Story (1995)|\n",
      "|      2|      Jumanji (1995)|\n",
      "|      3|Grumpier Old Men ...|\n",
      "|      4|Waiting to Exhale...|\n",
      "|      5|Father of the Bri...|\n",
      "|      6|         Heat (1995)|\n",
      "|      7|      Sabrina (1995)|\n",
      "|      8| Tom and Huck (1995)|\n",
      "|      9| Sudden Death (1995)|\n",
      "|     10|    GoldenEye (1995)|\n",
      "|     11|American Presiden...|\n",
      "|     12|Dracula: Dead and...|\n",
      "|     13|        Balto (1995)|\n",
      "|     14|        Nixon (1995)|\n",
      "|     15|Cutthroat Island ...|\n",
      "|     16|       Casino (1995)|\n",
      "|     17|Sense and Sensibi...|\n",
      "|     18|   Four Rooms (1995)|\n",
      "|     19|Ace Ventura: When...|\n",
      "|     20|  Money Train (1995)|\n",
      "+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "> ratings\n",
      "root\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      "\n",
      "+------+-------+------+\n",
      "|userId|movieId|rating|\n",
      "+------+-------+------+\n",
      "|     1|      1|   4.0|\n",
      "|     1|      3|   4.0|\n",
      "|     1|      6|   4.0|\n",
      "|     1|     47|   5.0|\n",
      "|     1|     50|   5.0|\n",
      "|     1|     70|   3.0|\n",
      "|     1|    101|   5.0|\n",
      "|     1|    110|   4.0|\n",
      "|     1|    151|   5.0|\n",
      "|     1|    157|   5.0|\n",
      "|     1|    163|   5.0|\n",
      "|     1|    216|   5.0|\n",
      "|     1|    223|   3.0|\n",
      "|     1|    231|   5.0|\n",
      "|     1|    235|   4.0|\n",
      "|     1|    260|   5.0|\n",
      "|     1|    296|   3.0|\n",
      "|     1|    316|   3.0|\n",
      "|     1|    333|   5.0|\n",
      "|     1|    349|   4.0|\n",
      "+------+-------+------+\n",
      "only showing top 20 rows\n",
      "\n",
      "> tags\n",
      "root\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- tag: string (nullable = true)\n",
      "\n",
      "+------+-------+--------+\n",
      "|userId|movieId|     tag|\n",
      "+------+-------+--------+\n",
      "|     2|  60756|   funny|\n",
      "|     2|  60756|  highly|\n",
      "|     2|  60756|quotable|\n",
      "|     2|  60756|    will|\n",
      "|     2|  60756| ferrell|\n",
      "|     2|  89774|  boxing|\n",
      "|     2|  89774|   story|\n",
      "|     2|  89774|     mma|\n",
      "|     2|  89774|     tom|\n",
      "|     2|  89774|   hardy|\n",
      "|     2| 106782|   drugs|\n",
      "|     2| 106782|leonardo|\n",
      "|     2| 106782|dicaprio|\n",
      "|     2| 106782|  martin|\n",
      "|     2| 106782|scorsese|\n",
      "|     7|  48516|     way|\n",
      "|     7|  48516|     too|\n",
      "|     7|  48516|    long|\n",
      "|    18|    431|      al|\n",
      "|    18|    431|  pacino|\n",
      "+------+-------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "bucket = 'gs://bddcc_up201405426' \n",
    "path = '/p1/'\n",
    "dataset = 'medium1'\n",
    "fullPath = bucket + path + dataset\n",
    "\n",
    "(movies, ratings, tags) = \\\n",
    "  loadMovieLensData(fullPath, format='csv', debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Test code \n",
    "\n",
    "__Include test code below that you may need here.__\n",
    "\n",
    "__The initial contents are only meant as an example.__\n",
    "\n",
    "__This section will NOT be evaluated.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+-------------------+\n",
      "|movieId|               title|                 JI|\n",
      "+-------+--------------------+-------------------+\n",
      "|    593|Silence of the La...| 0.4794952681388013|\n",
      "|    318|Shawshank Redempt...| 0.4388888888888889|\n",
      "|     50|Usual Suspects, T...| 0.4381625441696113|\n",
      "|     47|Seven (a.k.a. Se7...| 0.4117647058823529|\n",
      "|   2959|   Fight Club (1999)| 0.4053156146179402|\n",
      "|    356| Forrest Gump (1994)|0.38095238095238093|\n",
      "|   2571|  Matrix, The (1999)| 0.3746312684365782|\n",
      "|    858|Godfather, The (1...| 0.3720136518771331|\n",
      "|   1089|Reservoir Dogs (1...|0.35135135135135137|\n",
      "|    608|        Fargo (1996)| 0.3462897526501767|\n",
      "+-------+--------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#jiM = jiMovieSimilarity(ratings)\n",
    "#sm = recommendBySimilarity(296, movies, jiM)\n",
    "#sm.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommend by tag \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#jiM.orderBy(['JI','m1','m2'], ascending=[0,1,1]).show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jiM.cache()\n",
    "\n",
    "# Pulp Fiction\n",
    "#sm = recommendBySimilarity(296, movies, jiM)\n",
    "#sm.show()\n",
    "\n",
    "# Fight club\n",
    "#sm = recommendBySimilarity(2959, movies, jiM)\n",
    "#sm.show()\n",
    "    \n",
    "# Shrek\n",
    "#sm = recommendBySimilarity(4306, movies, jiM)\n",
    "#sm.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}